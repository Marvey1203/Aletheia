# Core Application & CLI
typer[all]==0.12.3
loguru==0.7.2
pydantic==2.8.2
rich==13.7.1

# Local LLM Interface
# Note: This is for the real model. It will work even if you don't have a GPU yet.
llama-cpp-python==0.2.79

# Dashboard / Observatory
streamlit==1.36.0


# IPC Communication
pyzmq==25.1.2